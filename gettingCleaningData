
MYSQL_HOME="C://Users/etsafe11/Desktop/R/"


#WEEK TWO - Reading from MySQL
#Installed RMySQL, which was a pain.  Then load RMySQL:
library(RMySQL)
#Then we open the UCSB genome databases
ucscDb <- dbConnect(MySQL(), user="genome", host="genome-mysql.cse.ucsc.edu")
result <- dbGetQuery(ucscDb, "show databases;") 
hg19 <- dbConnect(MySQL(), user="genome", db="hg19", 
                  host="genome-mysql.cse.ucsc.edu")
allTables <- dbListTables(hg19)
length(allTables)
allTables[1:5]
dbListFields(hg19, "affyU133Plus2")  #this lists all field in the affy table
#now we will count the observations in affy
#2nd argument is SQL command, not R
dbGetQuery(hg19, "select count(*) from affyU133Plus2")   
#now we will read from the table
affyData <- dbReadTable(hg19, "affyU133Plus2") #this step takes 5 min to load so be patient!
head(affyData)
#now, to do a SQL query, where you're only looking for a certain subset of the data:
query <- dbSendQuery(hg19, "select * from affyU133Plus2 where misMatches
                     between 1 and 3")
affyMis <- fetch(query)
quantile(affyMis$misMatches)
#this quantile above shows that our data is all between 1 and 3
#now we only select the top 10 records 
affyMisSmall <- fetch(query, n=10)
# we did this to test our work, without accidentally pulling in a huge file 
dim(affyMisSmall)
# MUST CLEAR QUERY AT END!
dbClearResult(query)
#MUST DISCONNECT AT THE END!!
dbDisconnect(ucscDb)



#WEEK TWO - Reading from HDF5
source("http://bioconductor.org/biocLite.R")
biocLite("rhdf5")
library(rhdf5)
created = h5createFile("example.h5")
created
created = h5createGroup("example.h5", "foo")
created = h5createGroup("example.h5", "baa")
created = h5createGroup("example.h5", "foo/foobaa")
h5ls("example.h5") #this lists out the contents
# Below is how you write a matrix to a group
A <- matrix(1:10, nr=5, nc=2)
h5write(A, "example.h5", "foo/A")
B <- array(seq(0.1, 2.0, by=0.1), dim=c(5,2,2))
attr(B, "scale") <- "liter"
h5write(B, "example.h5", "foo/foobaa/B")
h5ls("example.h5")
# Below is how you write an object df to a dataset
df = data.frame(1L:5L, seq(0, 1, length.out=5), c("ab", "cde", "fgi", "a", "s"),
                stringsAsFactors = FALSE)
h5write(df, "example.h5", "df")
h5ls("example.h5")
# Below is how you read the data
readA = h5read("example.h5", "foo/A")
readB = h5read("example.h5", "foo/foobaa/B")
readdf = h5read("example.h5", "df")
readA
# Writing and reading chunks
h5write(c(12, 13, 14), "example.h5", "foo/A", index=list(1:3, 1))
h5read("example.h5", "foo/A")

# Reading Data from the Web
# Getting data off webpages - readLines()
# This gets the html code from Jeff Leek's Google Scholar webpage
con = url("http://scholar.google.com/citations?user=HI-I6C0AAAAJ&hl=en")
htmlCode = readLines(con)
closer(con)
htmlCode
# at this point the html code is ugly, but let's use htmlTreeParse on it:
library(XML)
url <- "http://scholar.google.com/citations?user=HI-I6C0AAAAJ&hl=en"
html <- htmlTreeParse(url, useInternalNodes = TRUE)
xpathSApply(html, "//title", xmlValue)
xpathSApply(html, "//td[@id='col-citedby']", xmlValue) #this didn't seem to work
#GET from the httr package (so, doing the same as previous example but using httr package instead)
library(httr)
html2 = GET(url)
content2 = content(html2, as="text")
parsedHtml = htmlParse(content2, asText = TRUE)
xpathSApply(parsedHtml, "//title", xmlValue)
#Accessing websites with passwords
pg2 = GET("httpbin.org/basic-auth/user/passwd", authenticate("user", "passwd"))
pg2
names(pg2)
# Use handles!
google = handle("http://google.com")
pg1 = GET(handle=google, path="/")
pg2 = GET(handle=google, path="search")


